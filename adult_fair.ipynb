{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from fairness_checker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model back\n",
    "with open('./model/adult_synth.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/adult_RF.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X.to_numpy())\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.drop(labels=[\"workclass\", \"education\", \"occupation\", \"relationship\", \"race\", \"native.country\"], axis = 1, inplace = True)\n",
    "        df.drop(labels=[\"income\"], axis = 1, inplace = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes 10 minutes\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] == '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.1933447448 0.1082235768 0.0851211679 0.0014029132 1.7865307212\n",
      "accuracy_eqaulity   0.0250249201 0.1391474896 0.1141225695 0.0029940212 0.1798445676\n",
      "equalized_odds_1    0.0175621188 0.0875346615 0.0699725427 0.0016896592 0.2006304530\n",
      "equalized_odds_2    0.0114542011 0.0624741778 0.0510199767 0.0101231894 0.1833429674\n",
      "accuracy_equality_1 0.1941115666 0.1458089898 0.0483025769 0.0225247803 1.3312729684\n",
      "accuracy_equality_2 0.1102330179 0.1394989392 0.0292659214 0.0066585384 0.7902068537\n",
      "mean_difference     0.1801306340 0.1050887296 0.0750419043 0.0027038341 1.7140813728\n",
      "sum of diff: 0.4728466593515629\n",
      "avg of ratio: 0.8837014148906338\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/adult_LR.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.drop(labels=['income','native.country', 'hours.per.week'], axis = 1, inplace = True)\n",
    "        scaler = StandardScaler()\n",
    "        df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 10 minutes\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] == '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.0139228408 0.0284592240 0.0145363831 0.0028012685 0.4892206778\n",
      "accuracy_eqaulity   0.0992683727 0.1092422431 0.0099738705 0.0027937253 0.9086995087\n",
      "equalized_odds_1    0.0017247318 0.0119668633 0.0102421314 0.0024661815 0.1441256401\n",
      "equalized_odds_2    0.0080650603 0.0183612086 0.0102961483 0.0063934861 0.4392445227\n",
      "accuracy_equality_1 0.3459565225 0.1449367663 0.2010197562 0.0153266381 2.3869479862\n",
      "accuracy_equality_2 0.1120956978 0.1466942950 0.0345985972 0.0041668844 0.7641449028\n",
      "mean_difference     0.0678595096 0.0375924023 0.0302671072 0.0016941436 1.8051389460\n",
      "sum of diff: 0.310933993918111\n",
      "avg of ratio: 0.9910745977571719\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/adult_KNN.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df = df[['age', 'workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country']]\n",
    "        scaler = StandardScaler()\n",
    "        df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 20 mins!\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] == '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.1721440158 0.1046898005 0.0674542153 0.0047297522 1.6443246140\n",
      "accuracy_eqaulity   0.0473392149 0.1176936877 0.0703544728 0.0037954066 0.4022239072\n",
      "equalized_odds_1    0.0571962732 0.0786044106 0.0214081374 0.0048159543 0.7276471230\n",
      "equalized_odds_2    0.1667534959 0.1239259158 0.0428275801 0.0076650720 1.3455901845\n",
      "accuracy_equality_1 0.1009553523 0.1512929415 0.0503375892 0.0167325480 0.6672839543\n",
      "accuracy_equality_2 0.1193507001 0.1448488999 0.0254981998 0.0090541438 0.8239669072\n",
      "mean_difference     0.1654413724 0.1067693908 0.0586719816 0.0027132484 1.5495206177\n",
      "sum of diff: 0.3365521762158183\n",
      "avg of ratio: 1.022936758266558\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
