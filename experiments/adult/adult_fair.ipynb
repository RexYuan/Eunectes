{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from fairness_checker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# To load the model back\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/adult_synth.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# To load the model back\n",
    "with open('./model/adult_synth.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/adult_RF.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X.to_numpy())\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.drop(labels=[\"workclass\", \"education\", \"occupation\", \"relationship\", \"race\", \"native.country\"], axis = 1, inplace = True)\n",
    "        df.drop(labels=[\"income\"], axis = 1, inplace = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes 10 minutes\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] != '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.1933447448 0.1079348668 0.0854098779 0.0040380134 1.7913094299\n",
      "accuracy_eqaulity   0.0250249201 0.1402075623 0.1151826422 0.0036664884 0.1784848099\n",
      "equalized_odds_1    0.0175621188 0.0870924675 0.0695303487 0.0029624706 0.2016491127\n",
      "equalized_odds_2    0.0114542011 0.0615285897 0.0500743886 0.0151477887 0.1861606320\n",
      "accuracy_equality_1 0.1941115666 0.1479896782 0.0461218884 0.0139549399 1.3116561169\n",
      "accuracy_equality_2 0.1102330179 0.1460873949 0.0358543771 0.0039670596 0.7545689887\n",
      "mean_difference     0.1801306340 0.1036731077 0.0764575262 0.0034428245 1.7374865851\n",
      "sum of diff: 0.47863104912868565\n",
      "avg of ratio: 0.8801879536045281\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/adult_LR.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.drop(labels=['income','native.country', 'hours.per.week'], axis = 1, inplace = True)\n",
    "        scaler = StandardScaler()\n",
    "        df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 10 minutes\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] != '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.0139228408 0.0290808216 0.0151579808 0.0020812768 0.4787636686\n",
      "accuracy_eqaulity   0.0992683727 0.1102998148 0.0110314422 0.0043228626 0.8999867571\n",
      "equalized_odds_1    0.0017247318 0.0128049053 0.0110801734 0.0023301829 0.1346930565\n",
      "equalized_odds_2    0.0080650603 0.0240439068 0.0159788465 0.0073211533 0.3354305262\n",
      "accuracy_equality_1 0.3459565225 0.1521847909 0.1937717316 0.0168056408 2.2732660770\n",
      "accuracy_equality_2 0.1120956978 0.1432408776 0.0311451798 0.0074096416 0.7825677956\n",
      "mean_difference     0.0678595096 0.0364194480 0.0314400615 0.0025102616 1.8632767169\n",
      "sum of diff: 0.30960541579755535\n",
      "avg of ratio: 0.9668549425429421\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/adult_KNN.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df = df[['age', 'workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country']]\n",
    "        scaler = StandardScaler()\n",
    "        df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 20 mins!\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] != '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.1721440158 0.1042331497 0.0679108661 0.0036381468 1.6515284854\n",
      "accuracy_eqaulity   0.0473392149 0.1171415301 0.0698023152 0.0048074738 0.4041198272\n",
      "equalized_odds_1    0.0571962732 0.0790041813 0.0218079081 0.0044851970 0.7239651399\n",
      "equalized_odds_2    0.1667534959 0.1221507312 0.0446027647 0.0089484660 1.3651452947\n",
      "accuracy_equality_1 0.1009553523 0.1328899026 0.0319345504 0.0213990924 0.7596916716\n",
      "accuracy_equality_2 0.1193507001 0.1465997151 0.0272490150 0.0075578972 0.8141264125\n",
      "mean_difference     0.1654413724 0.1060179881 0.0594233844 0.0032167290 1.5605028491\n",
      "sum of diff: 0.32273080391905606\n",
      "avg of ratio: 1.0398685257764473\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
