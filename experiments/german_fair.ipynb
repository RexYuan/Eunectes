{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from fairness_checker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model back\n",
    "with open('./model/german_synth.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/german_XGB.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X.to_numpy())\n",
    "\n",
    "    def preprocessing(self, df_credit):\n",
    "\n",
    "        fixed_columns = [\n",
    "            'Purpose_1', 'Purpose_2', 'Purpose_3', 'Purpose_4', 'Purpose_5', 'Purpose_6', 'Purpose_7', 'Sex_1', 'Housing_1', 'Housing_2', 'Savings_1', 'Savings_2', 'Savings_3', 'Savings_4', 'Risk_1', 'Check_1', 'Check_2', 'Check_3', 'Age_cat_Young', 'Age_cat_Adult', 'Age_cat_Senior'\n",
    "        ]\n",
    "\n",
    "        # print(\"BEFORE\")\n",
    "        # print(df_credit.columns.tolist())\n",
    "        # print()\n",
    "\n",
    "        #Purpose to Dummies Variable\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit.Purpose, drop_first=True, prefix='Purpose'), left_index=True, right_index=True)\n",
    "        #Sex feature in dummies\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit.Sex, drop_first=True, prefix='Sex'), left_index=True, right_index=True)\n",
    "        # Housing get dummies\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit.Housing, drop_first=True, prefix='Housing'), left_index=True, right_index=True)\n",
    "        # Housing get Saving Accounts\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit[\"Saving accounts\"], drop_first=True, prefix='Savings'), left_index=True, right_index=True)\n",
    "        # Housing get Risk\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit.Risk, prefix='Risk', drop_first=True), left_index=True, right_index=True)\n",
    "        # Housing get Checking Account\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit[\"Checking account\"], drop_first=True, prefix='Check'), left_index=True, right_index=True)\n",
    "\n",
    "        interval = (18, 25, 35, 60, 120)\n",
    "        cats = ['Student', 'Young', 'Adult', 'Senior']\n",
    "        df_credit[\"Age_cat\"] = pd.cut(df_credit.Age, interval, labels=cats)\n",
    "\n",
    "        # Housing get Age categorical\n",
    "        df_credit = df_credit.merge(pd.get_dummies(df_credit[\"Age_cat\"], drop_first=True, prefix='Age_cat'), left_index=True, right_index=True)\n",
    "\n",
    "        for col in fixed_columns:\n",
    "            if col not in df_credit.columns:\n",
    "                # print(\"Added col\", col)\n",
    "                df_credit[col] = 0\n",
    "\n",
    "        #Excluding the missing columns\n",
    "        del df_credit[\"Saving accounts\"]\n",
    "        del df_credit[\"Checking account\"]\n",
    "        del df_credit[\"Purpose\"]\n",
    "        del df_credit[\"Sex\"]\n",
    "        del df_credit[\"Housing\"]\n",
    "        del df_credit[\"Age_cat\"]\n",
    "        del df_credit[\"Risk\"]\n",
    "        # del df_credit['Risk_0']\n",
    "\n",
    "        df_credit['Credit amount'] = np.log(df_credit['Credit amount'])\n",
    "\n",
    "        df_credit = df_credit.drop('Risk_1', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"AFTER\")\n",
    "        # print(df_credit.columns.tolist())\n",
    "        # print()\n",
    "\n",
    "        # current_features = df_credit.columns.tolist()\n",
    "\n",
    "        # missing_features = set(current_features) - set(trained_features)\n",
    "        # print(\"Missing features:\", missing_features)\n",
    "\n",
    "        return df_credit\n",
    "\n",
    "trained = model_wrapper(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "iter: 5\n"
     ]
    }
   ],
   "source": [
    "# this takes 10 minutes\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for i in range(iter):\n",
    "    if i % 5 == 0:\n",
    "        print(\"iter:\", i)\n",
    "    synth = model.synthetic_data(rows=1000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['Sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['Risk'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['Job'] == x), ('1',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/local/anaconda3/envs/mbi/lib/python3.13/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/german_processed.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['Sex'] != '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['Risk'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['Job'] == x), ('1',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std          ratio\n",
      "demographic_parity  0.0148200094 0.1359467888 0.1211267794 0.0112536747 0.1090133094\n",
      "accuracy_eqaulity   0.0543712015 0.2217233727 0.1673521712 0.0133237331 0.2452208842\n",
      "equalized_odds_1    0.0478889476 0.0785245730 0.0306356254 0.0179392661 0.6098593828\n",
      "equalized_odds_2    0.0691931126 0.1998193924 0.1306262798 0.1135920407 0.3462782654\n",
      "accuracy_equality_1 0.1205673759 0.1122169166 0.0083504593 0.0375831250 1.0744135511\n",
      "accuracy_equality_2 0.0278110765 0.1392699054 0.1114588289 0.0688667636 0.1996919320\n",
      "mean_difference     0.2570827489 0.1723787715 0.0847039775 0.0198112074 1.4913828815\n",
      "sum of diff: 0.6542541213907759\n",
      "avg of ratio: 0.5822657437755332\n"
     ]
    }
   ],
   "source": [
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std         \", \"ratio\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", f\"{np.std(np.array(demographic_parity)):.10f}\", f\"{og_demographic_parity / np.mean(np.array(demographic_parity)):.10f}\")\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", f\"{np.std(np.array(accuracy_eqaulity)):.10f}\", f\"{og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity)):.10f}\")\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", f\"{np.std(np.array(equalized_odds_1)):.10f}\", f\"{og_equalized_odds_1 / np.mean(np.array(equalized_odds_1)):.10f}\")\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", f\"{np.std(np.array(equalized_odds_2)):.10f}\", f\"{og_equalized_odds_2 / np.mean(np.array(equalized_odds_2)):.10f}\")\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\")\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", f\"{np.std(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\")\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", f\"{np.std(np.array(mean_difference)):.10f}\", f\"{og_mean_difference / np.mean(np.array(mean_difference)):.10f}\")\n",
    "\n",
    "print(\n",
    "\"sum of diff:\",\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")\n",
    "\n",
    "print(\n",
    "\"avg of ratio:\",\n",
    "(og_demographic_parity / np.mean(np.array(demographic_parity))+\n",
    "og_accuracy_eqaulity / np.mean(np.array(accuracy_eqaulity))+\n",
    "og_equalized_odds_1 / np.mean(np.array(equalized_odds_1))+\n",
    "og_equalized_odds_2 / np.mean(np.array(equalized_odds_2))+\n",
    "og_conditional_use_accuracy_equality_1 / np.mean(np.array(conditional_use_accuracy_equality_1))+\n",
    "og_conditional_use_accuracy_equality_2 / np.mean(np.array(conditional_use_accuracy_equality_2))+\n",
    "og_mean_difference / np.mean(np.array(mean_difference))) / 7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
