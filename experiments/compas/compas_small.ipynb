{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "\n",
    "from mbi import (\n",
    "    Dataset,\n",
    "    FactoredInference,\n",
    "    Domain,\n",
    "    LocalInference,\n",
    "    MixtureInference,\n",
    "    PublicInference,\n",
    ")\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from fairness_checker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_cat</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>is_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_cat  sex  race  is_recid\n",
       "0        1    1     5         0\n",
       "1        1    1     5         0\n",
       "2        0    1     2        -1\n",
       "3        0    1     0         1\n",
       "4        2    1     0         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://www.kaggle.com/datasets/danofer/compass\n",
    "df = pd.read_csv(\"./data/compas_og.csv\")\n",
    "df.head()\n",
    "\n",
    "# source: https://www.kaggle.com/code/innocentsky/logistics-regression-compas-recidivism-racial-bias\n",
    "columns_to_drop = ['id', 'first', 'last', 'in_custody', 'vr_charge_desc', 'r_case_number', 'vr_charge_degree',\n",
    "                   'c_offense_date', 'c_case_number', 'r_offense_date', 'juv_other_count', 'end', 'event',\n",
    "                   'screening_date', 'start', 'juv_misd_count', 'juv_fel_count', 'r_days_from_arrest',\n",
    "                   'r_charge_degree', 'days_b_screening_arrest', 'vr_case_number', 'priors_count.1', 'r_jail_out',\n",
    "                   'c_arrest_date', 'r_charge_desc', 'r_jail_in', 'violent_recid', 'decile_score.1',\n",
    "                   'vr_offense_date', 'out_custody']\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "df['c_jail_in'] = pd.to_datetime(df['c_jail_in'], dayfirst=True)\n",
    "df['c_jail_out'] = pd.to_datetime(df['c_jail_out'], dayfirst=True)\n",
    "df['compas_screening_date'] = pd.to_datetime(df['compas_screening_date'], dayfirst=True)\n",
    "df['v_screening_date'] = pd.to_datetime(df['v_screening_date'], dayfirst=True)\n",
    "df['days_in_jail'] = abs((df['c_jail_out'] - df['c_jail_in']).dt.days)\n",
    "\n",
    "numeric_cols = ['c_days_from_compas', 'v_decile_score',]\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "categorical_cols = ['c_charge_degree', 'score_text', 'v_score_text', 'c_jail_in', 'c_jail_out', 'c_charge_desc', 'days_in_jail']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "df_small = df[[\"age_cat\", \"sex\", \"race\", \"is_recid\"]].copy()\n",
    "\n",
    "columns_to_encode = ['age_cat', 'sex', 'race']\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column in columns_to_encode:\n",
    "    df_small[column] = le.fit_transform(df_small[column])\n",
    "\n",
    "df_small.to_csv('./data/compas_processed_small.csv', index=False)\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5659690627843494\n"
     ]
    }
   ],
   "source": [
    "dataset_small = pd.read_csv(\"./data/compas_processed_small.csv\")\n",
    "\n",
    "X_small = dataset_small[[\"age_cat\", \"sex\", \"race\"]].copy()\n",
    "Y_small = dataset_small['is_recid']\n",
    "\n",
    "X_train_small, X_test_small, Y_train_small, Y_test_small = train_test_split(X_small, Y_small, test_size=0.3,\n",
    "                                                    stratify=X_small[['race']], random_state=42)\n",
    "\n",
    "clf_small = RandomForestClassifier(\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=50\n",
    "    )\n",
    "\n",
    "clf_small.fit(X_train_small, Y_train_small)\n",
    "\n",
    "test_accuracy = clf_small.score(X_test_small, Y_test_small)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "with open('./model/compas_RF_small.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_small, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clique size: 108\n",
      "iteration\t\ttime\t\tl1_loss\t\tl2_loss\t\tfeasibility\n",
      "0.00\t\t0.00\t\t7791.95\t\t634057.27\t\t0.00\n",
      "50.00\t\t0.22\t\t255.34\t\t753.78\t\t0.00\n",
      "100.00\t\t0.45\t\t227.04\t\t695.66\t\t0.00\n",
      "150.00\t\t0.69\t\t223.61\t\t691.56\t\t0.00\n",
      "200.00\t\t0.90\t\t222.11\t\t689.75\t\t0.00\n",
      "250.00\t\t1.12\t\t221.16\t\t688.47\t\t0.00\n",
      "300.00\t\t1.34\t\t220.54\t\t687.47\t\t0.00\n",
      "350.00\t\t1.55\t\t220.07\t\t686.65\t\t0.00\n",
      "400.00\t\t1.78\t\t219.70\t\t685.99\t\t0.00\n",
      "450.00\t\t1.99\t\t219.39\t\t685.47\t\t0.00\n"
     ]
    }
   ],
   "source": [
    "data_small = Dataset.load(\"./data/compas_processed_small.csv\", \"./data/compas_processed_small.json\")\n",
    "domain_small = data_small.domain\n",
    "total = data_small.df.shape[0]\n",
    "\n",
    "# fully connected graph\n",
    "fields = list(data_small.domain)\n",
    "cliques = [\n",
    "    (fields[i], fields[j]) for i in range(len(fields)) for j in range(i+1, len(fields))\n",
    "]\n",
    "\n",
    "# spend half of privacy budget to measure all 1 way marginals\n",
    "np.random.seed(0)\n",
    "\n",
    "epsilon = 1.0\n",
    "epsilon_split = epsilon / (len(data_small.domain) + len(cliques))\n",
    "sigma = 2.0 / epsilon_split\n",
    "\n",
    "measurements = []\n",
    "for col in data_small.domain:\n",
    "    x = data_small.project(col).datavector()\n",
    "    y = x + np.random.laplace(loc=0, scale=sigma, size=x.size)\n",
    "    I = sparse.eye(x.size)\n",
    "    measurements.append((I, y, sigma, (col,)))\n",
    "\n",
    "# spend half of privacy budget to measure some more 2 and 3 way marginals\n",
    "for cl in cliques:\n",
    "    x = data_small.project(cl).datavector()\n",
    "    y = x + np.random.laplace(loc=0, scale=sigma, size=x.size)\n",
    "    I = sparse.eye(x.size)\n",
    "    measurements.append((I, y, sigma, cl))\n",
    "\n",
    "engine = FactoredInference(domain_small, log=True, iters=500)\n",
    "model = engine.estimate(measurements, total=total)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('./model/compas_synth_small.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std\n",
      "demographic_parity  0.5486594482 0.5511897117 0.0025302635 7.064220366964755e-05\n",
      "accuracy_eqaulity   0.0521064440 0.0436973164 0.0084091275 8.964695473530937e-05\n",
      "equalized_odds_1    0.4656165590 0.4764343778 0.0108178187 0.0001308542902427566\n",
      "equalized_odds_2    0.6367930420 0.6282030090 0.0085900330 8.481207977335857e-05\n",
      "accuracy_equality_1 0.4908039158 0.1287840150 0.3620199008 0.07389679712419607\n",
      "accuracy_equality_2 0.1602493012 0.1179371391 0.0423121621 0.011589581430400644\n",
      "mean_difference     0.4511876964 0.4516402045 0.0004525080 0.0011989953319592151\n",
      "0.4351318136398984\n"
     ]
    }
   ],
   "source": [
    "# To load the model back\n",
    "with open('./model/compas_RF_small.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('./model/compas_synth_small.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df = df[[\"age_cat\", \"sex\", \"race\"]].copy()\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)\n",
    "\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=70000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['is_recid'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )\n",
    "\n",
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/compas_processed_small.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] == '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['is_recid'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['race'] == x), ('4',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "\n",
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", np.std(np.array(demographic_parity)))\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", np.std(np.array(accuracy_eqaulity)))\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", np.std(np.array(equalized_odds_1)))\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", np.std(np.array(equalized_odds_2)))\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", np.std(np.array(conditional_use_accuracy_equality_1)))\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", np.std(np.array(conditional_use_accuracy_equality_2)))\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", np.std(np.array(mean_difference)))\n",
    "\n",
    "print(\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
