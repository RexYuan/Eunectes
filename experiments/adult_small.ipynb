{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "\n",
    "from mbi import (\n",
    "    Dataset,\n",
    "    FactoredInference,\n",
    "    Domain,\n",
    "    LocalInference,\n",
    "    MixtureInference,\n",
    "    PublicInference,\n",
    ")\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from fairness_checker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education.num  marital.status  sex  hours.per.week  income\n",
       "0   72              8               0    1              39       0\n",
       "1   65              8               0    1              17       0\n",
       "2   49              9               0    1              39       0\n",
       "3   37              3               0    1              39       0\n",
       "4   24              9               0    1              39       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://www.kaggle.com/datasets/uciml/adult-census-income/data\n",
    "dataset = pd.read_csv(\"./data/adult_og.csv\")\n",
    "dataset.head()\n",
    "\n",
    "# Convert Sex value to 0 and 1\n",
    "dataset[\"sex\"] = dataset[\"sex\"].map({\"Male\": 0, \"Female\":1})\n",
    "\n",
    "# Create Married Column - Binary Yes(1) or No(0)\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 'Married')\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].map({\"Married\":1, \"Single\":0})\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].astype(int)\n",
    "dataset['income'] = dataset['income'].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "columns_to_encode = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column in columns_to_encode:\n",
    "    dataset[column] = le.fit_transform(dataset[column])\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "# Drop the data you don't want to use\n",
    "dataset_small = dataset.copy()\n",
    "dataset_small.drop(labels=[\"workclass\",\"education\",\"occupation\",\"relationship\",\"race\",\"native.country\"], axis = 1, inplace = True)\n",
    "dataset_small.drop(labels=[\"fnlwgt\",\"capital.gain\",\"capital.loss\"], axis = 1, inplace = True)\n",
    "\n",
    "dataset_small.to_csv('./data/adult_processed_small.csv', index=False)\n",
    "dataset_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8082296944572394\n"
     ]
    }
   ],
   "source": [
    "dataset_small = pd.read_csv(\"./data/adult_processed_small.csv\")\n",
    "\n",
    "X_small = dataset_small[[\"age\", \"education.num\", \"marital.status\", \"sex\", \"hours.per.week\"]].copy()\n",
    "Y_small = dataset_small['income']\n",
    "\n",
    "X_train_small, X_test_small, Y_train_small, Y_test_small = train_test_split(X_small, Y_small, test_size=0.2, random_state=7)\n",
    "\n",
    "clf_small = RandomForestClassifier(\n",
    "        n_estimators=250,\n",
    "        max_features=4\n",
    "    )\n",
    "\n",
    "clf_small.fit(X_train_small, Y_train_small)\n",
    "\n",
    "test_accuracy = clf_small.score(X_test_small, Y_test_small)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "with open('./model/adult_RF_small.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_small, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clique size: 878336\n",
      "iteration\t\ttime\t\tl1_loss\t\tl2_loss\t\tfeasibility\n",
      "0.00\t\t0.00\t\t23239.12\t\t473062.72\t\t0.00\n",
      "50.00\t\t10.62\t\t11926.47\t\t13136.75\t\t0.00\n",
      "100.00\t\t25.41\t\t10931.10\t\t10907.11\t\t0.00\n",
      "150.00\t\t39.82\t\t10671.36\t\t10469.35\t\t0.00\n",
      "200.00\t\t54.02\t\t10519.53\t\t10229.52\t\t0.00\n",
      "250.00\t\t67.26\t\t10423.80\t\t10063.28\t\t0.00\n",
      "300.00\t\t80.61\t\t10345.12\t\t9929.22\t\t0.00\n",
      "350.00\t\t95.15\t\t10290.00\t\t9821.02\t\t0.00\n",
      "400.00\t\t109.87\t\t10240.06\t\t9725.26\t\t0.00\n",
      "450.00\t\t124.62\t\t10200.80\t\t9646.04\t\t0.00\n"
     ]
    }
   ],
   "source": [
    "data_small = Dataset.load(\"./data/adult_processed_small.csv\", \"./data/adult_processed_small.json\")\n",
    "domain_small = data_small.domain\n",
    "total = data_small.df.shape[0]\n",
    "\n",
    "# fully connected graph\n",
    "fields = list(data_small.domain)\n",
    "cliques = [\n",
    "    (fields[i], fields[j]) for i in range(len(fields)) for j in range(i+1, len(fields))\n",
    "]\n",
    "\n",
    "# spend half of privacy budget to measure all 1 way marginals\n",
    "np.random.seed(0)\n",
    "\n",
    "epsilon = 1.0\n",
    "epsilon_split = epsilon / (len(data_small.domain) + len(cliques))\n",
    "sigma = 2.0 / epsilon_split\n",
    "\n",
    "measurements = []\n",
    "for col in data_small.domain:\n",
    "    x = data_small.project(col).datavector()\n",
    "    y = x + np.random.laplace(loc=0, scale=sigma, size=x.size)\n",
    "    I = sparse.eye(x.size)\n",
    "    measurements.append((I, y, sigma, (col,)))\n",
    "\n",
    "# spend half of privacy budget to measure some more 2 and 3 way marginals\n",
    "for cl in cliques:\n",
    "    x = data_small.project(cl).datavector()\n",
    "    y = x + np.random.laplace(loc=0, scale=sigma, size=x.size)\n",
    "    I = sparse.eye(x.size)\n",
    "    measurements.append((I, y, sigma, cl))\n",
    "\n",
    "engine = FactoredInference(domain_small, log=True, iters=500)\n",
    "model = engine.estimate(measurements, total=total)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('./model/adult_synth_small.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                og           synth        diff         std\n",
      "demographic_parity  0.1794590492 0.1644071458 0.0150519034 0.0015610252491575218\n",
      "accuracy_eqaulity   0.1073618804 0.1186453820 0.0112835016 0.001860403129945866\n",
      "equalized_odds_1    0.0709861889 0.0760730500 0.0050868610 0.0018632981056573932\n",
      "equalized_odds_2    0.0114556016 0.1594259566 0.1479703550 0.006261589742373502\n",
      "accuracy_equality_1 0.1956401683 0.1986465833 0.0030064150 0.014396901512254407\n",
      "accuracy_equality_2 0.1256246141 0.2012349033 0.0756102893 0.004239971965642017\n",
      "mean_difference     0.1635085994 0.1411724776 0.0223361218 0.002030475289693193\n",
      "0.28034544711468884\n"
     ]
    }
   ],
   "source": [
    "# To load the model back\n",
    "with open('./model/adult_RF_small.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('./model/adult_synth_small.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "class model_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        X = self.preprocessing(df)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df = df[[\"age\", \"education.num\", \"marital.status\", \"sex\", \"hours.per.week\"]].copy()\n",
    "\n",
    "        return df\n",
    "\n",
    "trained = model_wrapper(clf)\n",
    "\n",
    "iter = 10\n",
    "\n",
    "disparate_impact = []\n",
    "demographic_parity = []\n",
    "equalized_odds_1, equalized_odds_2 = [], []\n",
    "equal_opportunity = []\n",
    "accuracy_eqaulity = []\n",
    "predictive_parity = []\n",
    "equal_calibration = []\n",
    "conditional_statistical_parity = []\n",
    "predictive_equality = []\n",
    "conditional_use_accuracy_equality_1, conditional_use_accuracy_equality_2 = [], []\n",
    "positive_balance = []\n",
    "negative_balance = []\n",
    "mean_difference = []\n",
    "\n",
    "for _ in range(iter):\n",
    "    synth = model.synthetic_data(rows=30000)\n",
    "    sdf = synth.df\n",
    "    sdf.to_csv('./tmp/synth.csv', index=False)\n",
    "\n",
    "    c = fairness_model_checker(\"./tmp/synth.csv\", verbose=False)\n",
    "\n",
    "    privileged_predicate = lambda row: row['sex'] != '0'\n",
    "    positive_predicate = lambda Y: Y == 1\n",
    "    truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "    disparate_impact               .append( c.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    demographic_parity             .append( c.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True) )\n",
    "    (x1, x2) = c.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    equalized_odds_1 .append( x1 )\n",
    "    equalized_odds_2 .append( x2 )\n",
    "    equal_opportunity              .append( c.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    accuracy_eqaulity              .append( c.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    predictive_parity              .append( c.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    # equal_calibration (n/a)\n",
    "    conditional_statistical_parity .append( c.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['marital.status'] == x), ('0',), value=True) )\n",
    "    predictive_equality            .append( c.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True) )\n",
    "    (y1, y2) = c.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "    conditional_use_accuracy_equality_1 .append( y1 )\n",
    "    conditional_use_accuracy_equality_2 .append( y2 )\n",
    "    # positive_balance (n/a)\n",
    "    # negative_balance (n/a)\n",
    "    mean_difference .append( c.mean_difference(0.2,trained, privileged_predicate, positive_predicate, value=True) )\n",
    "\n",
    "og_disparate_impact = 0\n",
    "og_demographic_parity = 0\n",
    "og_equalized_odds_1, og_equalized_odds_2 = 0, 0\n",
    "og_equal_opportunity = 0\n",
    "og_accuracy_eqaulity = 0\n",
    "og_predictive_parity = 0\n",
    "og_equal_calibration = 0\n",
    "og_conditional_statistical_parity = 0\n",
    "og_predictive_equality = 0\n",
    "og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2 = 0, 0\n",
    "og_positive_balance = 0\n",
    "og_negative_balance = 0\n",
    "og_mean_difference = 0\n",
    "\n",
    "cog = fairness_model_checker(\"./data/adult_processed_small.csv\", verbose=False)\n",
    "\n",
    "privileged_predicate = lambda row: row['sex'] == '0'\n",
    "positive_predicate = lambda Y: Y == 1\n",
    "truth_predicate = lambda row: row['income'] == '1'\n",
    "\n",
    "og_disparate_impact = cog.disparate_impact(0.8, trained, privileged_predicate, positive_predicate, value=True)\n",
    "og_demographic_parity = cog.demographic_parity(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "(og_equalized_odds_1, og_equalized_odds_2) = cog.equalized_odds(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_equal_opportunity = cog.equal_opportunity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_accuracy_eqaulity = cog.accuracy_eqaulity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "og_predictive_parity = cog.predictive_parity(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# equal_calibration (n/a)\n",
    "og_conditional_statistical_parity = cog.conditional_statistical_parity(0.2, trained, privileged_predicate, positive_predicate, lambda x: (lambda row: row['marital.status'] == x), ('0',), value=True)\n",
    "og_predictive_equality = cog.predictive_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "(og_conditional_use_accuracy_equality_1, og_conditional_use_accuracy_equality_2) = cog.conditional_use_accuracy_equality(0.2, trained, privileged_predicate, positive_predicate, truth_predicate, value=True)\n",
    "# positive_balance (n/a)\n",
    "# negative_balance (n/a)\n",
    "og_mean_difference = cog.mean_difference(0.2, trained, privileged_predicate, positive_predicate, value=True)\n",
    "\n",
    "print(\"name               \", \"og          \", \"synth       \", \"diff        \", \"std\")\n",
    "print(\"demographic_parity \", f\"{og_demographic_parity:.10f}\", f\"{np.mean(np.array(demographic_parity)):.10f}\", f\"{abs(og_demographic_parity - np.mean(np.array(demographic_parity))):.10f}\", np.std(np.array(demographic_parity)))\n",
    "print(\"accuracy_eqaulity  \", f\"{og_accuracy_eqaulity:.10f}\", f\"{np.mean(np.array(accuracy_eqaulity)):.10f}\", f\"{abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity))):.10f}\", np.std(np.array(accuracy_eqaulity)))\n",
    "print(\"equalized_odds_1   \", f\"{og_equalized_odds_1:.10f}\", f\"{np.mean(np.array(equalized_odds_1)):.10f}\", f\"{abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1))):.10f}\", np.std(np.array(equalized_odds_1)))\n",
    "print(\"equalized_odds_2   \", f\"{og_equalized_odds_2:.10f}\", f\"{np.mean(np.array(equalized_odds_2)):.10f}\", f\"{abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2))):.10f}\", np.std(np.array(equalized_odds_2)))\n",
    "print(\"accuracy_equality_1\", f\"{og_conditional_use_accuracy_equality_1:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_1)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1))):.10f}\", np.std(np.array(conditional_use_accuracy_equality_1)))\n",
    "print(\"accuracy_equality_2\", f\"{og_conditional_use_accuracy_equality_2:.10f}\", f\"{np.mean(np.array(conditional_use_accuracy_equality_2)):.10f}\", f\"{abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2))):.10f}\", np.std(np.array(conditional_use_accuracy_equality_2)))\n",
    "print(\"mean_difference    \", f\"{og_mean_difference:.10f}\", f\"{np.mean(np.array(mean_difference)):.10f}\", f\"{abs(og_mean_difference - np.mean(np.array(mean_difference))):.10f}\", np.std(np.array(mean_difference)))\n",
    "\n",
    "print(\n",
    "abs(og_demographic_parity - np.mean(np.array(demographic_parity)))+\n",
    "abs(og_accuracy_eqaulity - np.mean(np.array(accuracy_eqaulity)))+\n",
    "abs(og_equalized_odds_1 - np.mean(np.array(equalized_odds_1)))+\n",
    "abs(og_equalized_odds_2 - np.mean(np.array(equalized_odds_2)))+\n",
    "abs(og_conditional_use_accuracy_equality_1 - np.mean(np.array(conditional_use_accuracy_equality_1)))+\n",
    "abs(og_conditional_use_accuracy_equality_2 - np.mean(np.array(conditional_use_accuracy_equality_2)))+\n",
    "abs(og_mean_difference - np.mean(np.array(mean_difference)))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
